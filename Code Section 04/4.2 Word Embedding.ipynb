{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8439e-01, -2.7711e-01, -2.1512e-01,  1.5754e-01, -2.1959e-01,\n",
       "        9.4332e-02,  2.6961e-01,  3.6979e-01,  2.5089e-01,  2.4003e+00,\n",
       "        2.2686e-01, -8.2376e-02, -1.1064e-01,  6.8004e-02, -2.2015e-01,\n",
       "        2.9869e-01, -3.0817e-01, -2.7778e-01, -1.8559e-01, -1.1452e-01,\n",
       "       -9.7908e-02, -5.1572e-01, -1.8414e-01, -1.1982e-01, -2.0530e-01,\n",
       "       -2.0258e-01, -8.0844e-02, -5.9936e-02,  5.6478e-02, -4.1721e-02,\n",
       "       -9.7724e-02,  1.1624e-01, -3.4658e-01, -2.6188e-02,  1.2965e-01,\n",
       "       -5.9624e-02,  2.7778e-01, -1.4413e-01,  6.3775e-03,  1.7323e-01,\n",
       "        1.6473e-01, -8.8126e-02,  4.5344e-01, -2.8584e-01,  3.5856e-01,\n",
       "       -4.6877e-01, -1.1146e-01,  2.1928e-01,  3.3220e-01, -5.5807e-01,\n",
       "       -2.2855e-01,  3.4732e-01, -2.2626e-01,  2.9367e-01,  4.3566e-02,\n",
       "        3.6746e-01, -2.8908e-01,  1.8528e-01, -3.4961e-02,  9.7499e-03,\n",
       "        2.5176e-01, -2.0260e-02, -1.6895e-01, -6.0490e-01,  2.8381e-01,\n",
       "       -1.0313e-01,  4.7068e-02, -8.6688e-02,  4.6225e-01,  4.0169e-02,\n",
       "       -1.9505e-01, -1.2003e-01, -3.2950e-01, -6.5502e-02,  6.6521e-01,\n",
       "       -3.1048e-02,  3.3543e-01,  2.2243e-01,  1.7022e-01,  1.1484e-01,\n",
       "       -2.5259e-01, -2.9826e-01, -7.1158e-03,  5.8504e-01,  2.5600e-01,\n",
       "       -2.2230e-01,  7.3723e-02, -6.5927e-01, -5.8696e-01, -2.1480e-01,\n",
       "       -1.6414e-01,  2.3774e-01, -1.7176e-02,  5.6510e-01, -1.1530e-01,\n",
       "       -2.2981e-01, -4.0341e-01, -3.0086e-01,  1.9240e-02,  1.8588e-01,\n",
       "        3.6343e-01, -9.4269e-02, -1.2385e-01, -5.1850e-02, -1.5863e-01,\n",
       "       -8.4227e-01, -4.0958e-01,  8.9721e-02,  3.1663e-01,  2.7929e-01,\n",
       "        2.7285e-01, -3.1032e-01,  5.0027e-01, -6.0414e-01, -5.2290e-02,\n",
       "        4.5421e-01,  8.0382e-02,  3.6291e-01, -1.7694e-01, -2.6842e-01,\n",
       "        2.3606e-01, -6.8259e-01, -1.1284e-01,  7.5250e-02,  7.8801e-02,\n",
       "        6.7578e-02,  4.8819e-02,  8.8501e-02, -3.9709e-01,  1.1572e-01,\n",
       "        2.9796e-02,  3.2543e-01, -3.4351e-01,  9.0534e-02,  7.5966e-02,\n",
       "       -3.0974e-01, -5.9148e-01, -2.0137e-01,  4.5954e-01,  1.3488e-01,\n",
       "       -2.3103e+00,  4.8793e-02,  1.9174e-01,  2.5880e-02, -5.6198e-02,\n",
       "        1.0109e-01, -4.1789e-01,  6.5686e-01,  2.2553e-01, -6.5164e-02,\n",
       "       -1.8230e-01,  1.2914e-01,  1.7768e-01,  1.1695e-01, -8.7398e-02,\n",
       "       -1.7404e-02,  3.1230e-03,  1.1429e-01, -1.8833e-01, -2.7157e-01,\n",
       "        1.1142e-02, -2.1773e-01, -3.1534e-01,  7.9504e-01,  5.1270e-01,\n",
       "       -3.2645e-01,  9.7702e-02, -5.1564e-01, -4.8391e-01, -1.3354e-01,\n",
       "       -2.2792e-02,  2.0236e-01,  1.7445e-01, -2.6247e-02,  5.8216e-01,\n",
       "        1.1389e-01,  1.0705e-01, -4.1634e-01, -5.3028e-01,  3.9829e-01,\n",
       "       -3.9955e-01, -2.8530e-01,  5.7615e-01, -9.2854e-02,  1.1557e-01,\n",
       "       -2.6476e-01,  1.4108e-01, -1.3911e-02, -3.2183e-02, -1.5620e-01,\n",
       "       -1.9200e-01,  4.4624e-01,  1.4718e-01, -1.0945e-01, -2.2003e-01,\n",
       "        1.6683e-01,  4.3502e-01, -3.5025e-01,  1.1633e-01, -9.7531e-03,\n",
       "        3.4130e-01,  2.6923e-01,  1.7296e-02, -2.2520e-01,  1.2045e-01,\n",
       "        6.2976e-01, -2.4172e-01, -2.4435e-01,  3.3843e-03, -4.9939e-01,\n",
       "        2.0867e-01,  1.7625e-01, -3.5124e-01,  2.7435e-02,  7.3504e-03,\n",
       "        2.7606e-01,  2.8966e-01,  1.9049e-01,  9.6415e-02, -1.0620e-01,\n",
       "        5.9888e-03,  5.0891e-01,  7.2219e-01, -8.2658e-02,  3.4874e-01,\n",
       "       -2.1295e-01, -2.6478e-01, -2.7377e-01, -3.8049e-01, -5.0651e-01,\n",
       "        1.6694e-02, -6.7285e-02, -2.1868e-01,  3.2947e-03, -1.1054e-01,\n",
       "       -4.3233e-01, -2.5323e-01,  2.6341e-01,  3.1305e-01,  3.5979e-01,\n",
       "       -8.0950e-02, -2.9263e-01, -4.1474e-01, -9.4361e-02,  4.7541e-01,\n",
       "        4.9994e-01,  1.4337e-01, -1.5061e-01,  1.3262e-01,  1.6605e-01,\n",
       "        8.8708e-02,  4.7044e-01, -3.9076e-01,  1.9531e-01,  8.9540e-02,\n",
       "       -2.1483e-01, -7.6975e-02,  1.0654e-01, -1.7811e-01, -1.3079e-02,\n",
       "       -3.4195e-01, -2.5788e-04, -2.7651e-01, -4.4840e-01, -6.3388e-01,\n",
       "       -3.7084e-01,  6.9119e-01,  6.8392e-01, -1.9666e-01,  5.5074e-01,\n",
       "       -8.5473e-02,  8.6913e-02, -3.8673e-01,  2.1833e-01, -1.6739e-01,\n",
       "        3.0689e-01,  8.8089e-03, -8.2430e-02,  2.8268e-01,  1.6976e-01,\n",
       "       -3.8601e-02,  1.6133e-01, -3.0572e-01,  5.2853e-01, -1.1796e-01,\n",
       "       -1.0444e-01, -1.2491e-01, -6.6702e-02,  2.2006e-01,  2.6869e-01,\n",
       "       -5.7491e-01, -1.3014e-01, -5.5630e-01, -4.1474e-01, -7.3809e-02,\n",
       "        3.9172e-01,  5.5546e-01,  3.0281e-01, -3.1208e-01, -3.8065e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'brave').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8963e-01, -4.0309e-01,  3.5350e-01, -4.7907e-01, -4.3311e-01,\n",
       "        2.3857e-01,  2.6962e-01,  6.4332e-02,  3.0767e-01,  1.3712e+00,\n",
       "       -3.7582e-01, -2.2713e-01, -3.5657e-01, -2.5355e-01,  1.7543e-02,\n",
       "        3.3962e-01,  7.4723e-02,  5.1226e-01, -3.9759e-01,  5.1333e-03,\n",
       "       -3.0929e-01,  4.8911e-02, -1.8610e-01, -4.1702e-01, -8.1639e-01,\n",
       "       -1.6908e-01, -2.6246e-01, -1.5983e-02,  1.2479e-01, -3.7276e-02,\n",
       "       -5.7125e-01, -1.6296e-01,  1.2376e-01, -5.5464e-02,  1.3244e-01,\n",
       "        2.7519e-02,  1.2592e-01, -3.2722e-01, -4.9165e-01, -3.5559e-01,\n",
       "       -3.0630e-01,  6.1185e-02, -1.6932e-01, -6.2405e-02,  6.5763e-01,\n",
       "       -2.7925e-01, -3.0450e-03, -2.2400e-02, -2.8015e-01, -2.1975e-01,\n",
       "       -4.3188e-01,  3.9864e-02, -2.2102e-01, -4.2693e-02,  5.2748e-02,\n",
       "        2.8726e-01,  1.2315e-01, -2.8662e-02,  7.8294e-02,  4.6754e-01,\n",
       "       -2.4589e-01, -1.1064e-01,  7.2250e-02, -9.4980e-02, -2.7548e-01,\n",
       "       -5.4097e-01,  1.2823e-01, -8.2408e-02,  3.1035e-01, -6.3394e-02,\n",
       "       -7.3755e-01, -5.4992e-01,  9.9999e-02, -2.0758e-01, -3.9674e-02,\n",
       "        2.0664e-01, -9.7557e-02, -3.7092e-01,  2.7901e-01, -6.2218e-01,\n",
       "       -1.0280e-01,  2.3271e-01,  4.3838e-01,  3.2445e-02, -2.9866e-01,\n",
       "       -7.3611e-02,  7.1594e-01,  1.4241e-01,  2.7770e-01, -3.9892e-01,\n",
       "        3.6656e-02,  1.5759e-01,  8.2014e-02, -5.7343e-01,  3.5457e-01,\n",
       "        2.2491e-01, -6.2699e-01, -8.8106e-02,  2.4361e-01,  3.8533e-01,\n",
       "       -1.4083e-01,  1.7691e-01,  7.0897e-02,  1.7951e-01, -4.5907e-01,\n",
       "       -8.2120e-01, -2.6631e-02,  6.2549e-02,  4.2415e-01, -8.9630e-02,\n",
       "       -2.4654e-01,  1.4156e-01,  4.0187e-01, -4.1232e-01,  8.4516e-02,\n",
       "       -1.0626e-01,  7.3145e-01,  1.9217e-01,  1.4240e-01,  2.8511e-01,\n",
       "       -2.9454e-01, -2.1948e-01,  9.0460e-01, -1.9098e-01, -1.0340e+00,\n",
       "       -1.5754e-01, -1.1964e-01,  4.9888e-01, -1.0624e+00, -3.2820e-01,\n",
       "       -1.1232e-02, -7.9482e-01,  3.7275e-01, -6.8710e-03, -2.5772e-01,\n",
       "       -4.7005e-01, -4.1387e-01, -6.4089e-02, -2.8033e-01, -4.0778e-02,\n",
       "       -2.4866e+00,  6.2494e-03, -1.0210e-02,  1.2752e-01,  3.4965e-01,\n",
       "       -1.2571e-01,  3.1570e-01,  4.1926e-01,  2.0056e-01, -5.5984e-01,\n",
       "       -2.2801e-01,  1.2012e-01, -2.0518e-03, -8.9764e-02, -8.0373e-02,\n",
       "        1.1969e-02, -2.6978e-01,  3.4829e-01,  7.3664e-03, -1.1137e-01,\n",
       "        6.3410e-01,  3.8449e-01, -6.2248e-01,  4.1145e-02,  2.5922e-01,\n",
       "        6.5811e-01, -4.9548e-01, -1.3030e-01, -3.8279e-01,  1.1156e-01,\n",
       "       -4.3085e-01,  3.4473e-01,  2.7109e-02, -2.5108e-01, -2.8011e-01,\n",
       "        2.1662e-01,  3.2660e-01,  5.5895e-02,  7.6077e-02, -5.2480e-02,\n",
       "        4.5928e-02, -2.5266e-01,  5.2845e-01, -1.3145e-01, -1.2453e-01,\n",
       "        4.0556e-01,  3.1877e-01,  2.4415e-02, -2.2620e-01, -6.1960e-01,\n",
       "       -4.0886e-01, -3.5534e-02, -5.5123e-03,  2.3438e-01,  8.7854e-01,\n",
       "       -2.5161e-01,  4.0600e-01, -4.4284e-01,  3.4934e-01, -5.6429e-01,\n",
       "       -2.3676e-01,  6.2199e-01, -2.8175e-01,  4.2024e-01,  1.0043e-01,\n",
       "       -1.4720e-01,  4.9593e-01, -3.5850e-01, -1.3998e-01, -2.7494e-01,\n",
       "        2.3827e-01,  5.7268e-01,  7.9025e-02,  1.7872e-02, -2.1829e-01,\n",
       "        5.5050e-02, -5.4200e-01,  1.6788e-01,  3.9065e-01,  3.0209e-01,\n",
       "        2.3040e-01, -3.9351e-02, -2.1078e-01, -2.7224e-01,  1.6907e-01,\n",
       "        5.4819e-01,  9.4888e-02,  7.9798e-01, -6.6158e-02,  1.9844e-01,\n",
       "        2.0307e-01,  4.4808e-02, -1.0240e-01, -6.9909e-02, -3.6756e-02,\n",
       "        9.5159e-02, -2.7830e-01, -1.0597e-01, -1.6276e-01, -1.8211e-01,\n",
       "       -3.1897e-01, -2.1633e-01,  1.4994e-01, -7.2057e-02,  2.2264e-01,\n",
       "       -4.5551e-01,  3.0341e-01,  1.8431e-01,  2.1681e-01, -3.1940e-01,\n",
       "        2.6426e-01,  5.8106e-01,  5.4635e-02,  6.3238e-01,  4.3169e-01,\n",
       "        9.0343e-02,  1.9494e-01,  3.5483e-01, -2.0706e-02, -7.3117e-01,\n",
       "        1.2941e-01,  1.7418e-01, -1.5065e-01,  5.3355e-02,  4.4794e-02,\n",
       "       -1.6600e-01,  2.2007e-01, -5.3970e-01, -2.4968e-01, -2.6464e-01,\n",
       "       -5.5515e-01,  5.8242e-01,  2.2295e-01,  2.4433e-01,  4.5275e-01,\n",
       "        3.4693e-01,  1.2255e-01, -3.9059e-02, -3.2749e-01, -2.7891e-01,\n",
       "        1.3766e-01,  3.8392e-01,  1.0543e-03, -1.0242e-02,  4.9205e-01,\n",
       "       -1.7922e-01,  4.1215e-02,  1.3547e-01, -2.0598e-01, -2.3194e-01,\n",
       "       -7.7701e-01, -3.8237e-01, -7.6383e-01,  1.9418e-01, -1.5441e-01,\n",
       "        8.9740e-01,  3.0626e-01,  4.0376e-01,  2.1738e-01, -3.8050e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'lion').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp(u'lion').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.96635887e-01, -2.32740352e-03, -5.36607020e-02, -6.10564947e-02,\n",
       "       -4.08843048e-02,  1.45266443e-01, -1.08268000e-01, -6.27789786e-03,\n",
       "        1.48455709e-01,  1.90697408e+00, -2.57692993e-01, -1.95818534e-03,\n",
       "       -1.16141019e-02, -1.62858292e-01, -1.62938282e-01,  1.18210977e-02,\n",
       "        5.12646027e-02,  1.00078702e+00, -2.01447997e-02, -2.54611671e-01,\n",
       "       -1.28316596e-01, -1.97198763e-02, -2.89733019e-02, -1.94347113e-01,\n",
       "        1.26644447e-01, -8.69869068e-02, -2.20812604e-01, -1.58452198e-01,\n",
       "        9.86308008e-02, -1.79210991e-01, -1.55290633e-01,  1.95643142e-01,\n",
       "        2.66436003e-02, -1.64984968e-02,  1.18824698e-01, -1.17830629e-03,\n",
       "        4.99809943e-02, -4.23077159e-02, -3.86111848e-02, -7.47400150e-03,\n",
       "        1.23448208e-01,  9.60620027e-03, -3.32463719e-02, -1.77848607e-01,\n",
       "        1.19390726e-01,  1.87545009e-02, -1.84173390e-01,  6.91781715e-02,\n",
       "        1.28520593e-01,  1.48827005e-02, -1.78013414e-01,  1.10003807e-01,\n",
       "       -3.35464999e-02, -1.52476998e-02, -9.41195935e-02,  1.58633105e-02,\n",
       "       -1.29811959e-02,  1.40140295e-01, -1.47720069e-01, -3.81718054e-02,\n",
       "        4.66808230e-02,  3.31423879e-02,  7.97965974e-02,  1.60014004e-01,\n",
       "        8.90410226e-03, -1.01237908e-01,  7.39663988e-02,  2.47380026e-02,\n",
       "        4.26153988e-02,  9.66729969e-02,  2.87616011e-02,  7.22841993e-02,\n",
       "        1.76565602e-01,  7.55538046e-02,  1.10501610e-01, -1.02358103e-01,\n",
       "       -5.43345436e-02, -4.12176028e-02,  3.98623049e-02, -2.98339734e-03,\n",
       "       -5.32988012e-02,  1.90624595e-01, -6.42587021e-02, -1.76225007e-02,\n",
       "        3.94165330e-02, -1.14773512e-01,  4.25241649e-01,  2.07243040e-01,\n",
       "        2.60730416e-01,  1.31226778e-01, -8.00508037e-02,  6.88939020e-02,\n",
       "        7.05293044e-02, -1.10744104e-01,  4.14580032e-02,  5.13269613e-03,\n",
       "       -1.29179001e-01, -5.84542975e-02,  9.13560018e-02, -1.75975591e-01,\n",
       "        9.52741057e-02,  1.37699964e-02, -1.30865201e-01, -4.76420000e-02,\n",
       "        1.61670998e-01, -6.76959991e-01,  2.68619388e-01, -7.94106945e-02,\n",
       "        8.56394917e-02, -5.94138019e-02,  7.44821057e-02, -1.67490095e-01,\n",
       "        1.97447598e-01, -2.71580786e-01,  1.51915969e-02,  1.12019002e-01,\n",
       "       -4.32585999e-02, -1.03554968e-02,  6.33272156e-02,  5.20200143e-03,\n",
       "        4.94491048e-02, -1.07016601e-01, -6.45387918e-02, -1.76269561e-01,\n",
       "       -1.98135704e-01,  4.17800918e-02,  1.23686995e-02, -1.13280594e-01,\n",
       "       -4.03523073e-02, -4.21132054e-03, -9.65667963e-02, -7.12300017e-02,\n",
       "       -2.19088510e-01,  6.41715974e-02,  1.11634992e-01, -7.12868944e-02,\n",
       "       -8.27060193e-02,  1.53889004e-02,  6.84699565e-02, -5.50561920e-02,\n",
       "       -1.84788990e+00, -4.75010052e-02,  1.31487206e-01,  1.03359401e-01,\n",
       "        1.80857688e-01, -8.03041980e-02,  2.27739997e-02,  5.56868985e-02,\n",
       "        9.20986086e-02,  6.22248054e-02,  4.86670025e-02, -4.06427011e-02,\n",
       "        3.83703932e-02, -4.05869968e-02, -2.26339817e-01,  3.69174965e-02,\n",
       "       -1.30066186e-01,  1.27621710e-01,  2.76701003e-02, -1.39992401e-01,\n",
       "       -3.75526994e-02, -8.11104029e-02, -1.78196102e-01, -1.21652998e-01,\n",
       "       -5.88919744e-02, -1.06128812e-01, -4.72390745e-03, -1.14130601e-01,\n",
       "       -7.60087445e-02, -9.48704034e-02,  1.68780401e-01,  3.82669941e-02,\n",
       "       -1.68303996e-01, -1.30991384e-01, -2.46409744e-01,  1.42855030e-02,\n",
       "        1.23633012e-01,  7.95699935e-03, -3.22283022e-02,  3.75844017e-02,\n",
       "       -4.48104031e-02, -2.00578898e-01, -2.86081016e-01, -1.83181003e-01,\n",
       "       -5.46899159e-04,  6.52990937e-02,  2.34263036e-02, -7.60660022e-02,\n",
       "        1.13897599e-01, -7.05380812e-02,  1.30277812e-01,  2.83973999e-02,\n",
       "        1.73887815e-02, -1.71358977e-02,  1.78455990e-02,  1.86773703e-01,\n",
       "        1.83613986e-01, -4.05438878e-02,  1.28929759e-03, -3.71900201e-03,\n",
       "       -1.97373003e-01,  4.78463694e-02, -2.21408010e-01,  2.68826094e-02,\n",
       "        2.40951017e-01,  7.42616802e-02,  7.53984973e-02, -7.67349079e-02,\n",
       "       -5.37766796e-03, -8.06540065e-03,  1.88790001e-02,  8.31135064e-02,\n",
       "       -5.20760007e-02,  1.29393607e-01,  4.09864075e-02,  7.31946975e-02,\n",
       "       -1.64099425e-01,  1.17529690e-01, -6.96440935e-02,  1.91028208e-01,\n",
       "        1.01721905e-01,  6.34808987e-02, -8.29815865e-02, -6.95784390e-03,\n",
       "       -1.69757873e-01, -2.02478573e-01,  3.65395918e-02,  1.32345587e-01,\n",
       "        3.53013016e-02,  2.27603033e-01, -1.52753398e-01,  7.80210178e-03,\n",
       "        2.06879750e-02, -8.63540452e-03,  9.85722095e-02, -2.91380938e-02,\n",
       "       -1.42988954e-02, -9.39018354e-02,  1.43968105e-01,  7.82396942e-02,\n",
       "       -1.93540990e-01, -9.36544985e-02, -8.23533013e-02,  4.40272018e-02,\n",
       "       -2.22195080e-03, -1.29856914e-01, -1.53841600e-01, -1.55329984e-02,\n",
       "       -2.55266696e-01,  1.14425398e-01, -1.03161987e-02, -4.66439016e-02,\n",
       "       -5.69390282e-02,  7.72780031e-02,  1.28908500e-01,  1.61679000e-01,\n",
       "        1.50837511e-01,  6.18334934e-02, -9.06937942e-02, -3.52137014e-02,\n",
       "        1.35956988e-01,  7.52059072e-02,  5.73905036e-02, -1.65402606e-01,\n",
       "        1.68419987e-01, -1.83722824e-01,  5.91069926e-03, -1.25354990e-01,\n",
       "        3.95771042e-02,  5.67352995e-02, -5.63519308e-03,  1.53597593e-01,\n",
       "       -6.84822723e-02, -1.40976995e-01, -3.62732522e-02, -2.61475928e-02,\n",
       "        2.50091963e-02,  1.18994810e-01, -2.66857035e-02,  7.50442073e-02,\n",
       "        2.04583794e-01,  4.37736101e-02, -8.17096978e-02,  6.80228025e-02,\n",
       "        5.50465994e-02, -2.39979066e-02,  7.68290013e-02, -5.76773956e-02,\n",
       "        8.30340981e-02,  3.63199934e-02, -1.65820405e-01,  2.55408939e-02,\n",
       "       -5.30679002e-02, -1.35961995e-01, -1.03501797e-01,  1.36406809e-01,\n",
       "        9.66293067e-02,  7.33902007e-02, -1.83055893e-01, -2.73141060e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'The quick brown fox jumped over the lazy dogs.')\n",
    "\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion lion 1.0\n",
      "lion cat 0.52654374\n",
      "lion pet 0.39923766\n",
      "cat lion 0.52654374\n",
      "cat cat 1.0\n",
      "cat pet 0.7505456\n",
      "pet lion 0.39923766\n",
      "pet cat 0.7505456\n",
      "pet pet 1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'lion cat pet')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7401743668099329"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'man').similarity(nlp(u'woman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36166378256137205"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'man').similarity(nlp(u'tree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33908944525506207"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'woman').similarity(nlp(u'moon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3194349100251551"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'woman').similarity(nlp(u'flower'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20230062526712764"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'tree').similarity(nlp(u'brave'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7359829457249657"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'lion').similarity(nlp(u'tiger'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19291049251681294"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'lion').similarity(nlp(u'dandelion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6645507202157027"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'some').similarity(nlp(u'same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2194131798305039"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'piece').similarity(nlp(u'peace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6393098529633738"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'love').similarity(nlp(u'hate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3656781572377605"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'love').similarity(nlp(u'flower'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9394985344221137"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'I love school').similarity(nlp(u'I hate school'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9530413537844529"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'this film is awesome. I love it').similarity(nlp(u'this film is boring. I hate it'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like love 0.65790397\n",
      "like hate 0.6574652\n",
      "like flower 0.28307748\n",
      "love like 0.65790397\n",
      "love hate 0.6393099\n",
      "love flower 0.36567816\n",
      "hate like 0.6574652\n",
      "hate love 0.6393099\n",
      "hate flower 0.16520926\n",
      "flower like 0.28307748\n",
      "flower love 0.36567816\n",
      "flower hate 0.16520926\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'like love hate flower')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        if not token1 == token2 : \n",
    "            print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684831"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684831, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "nargle False 0.0 True\n",
      "hesham True 7.32903 False\n",
      "lksdvsk False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'dog cat nargle hesham lksdvsk')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word queen , has similarity 0.7880843877792358\n",
      "Word prince , has similarity 0.6401076912879944\n",
      "Word princess , has similarity 0.6125636100769043\n",
      "Word elizabeth , has similarity 0.4564860165119171\n",
      "Word crown , has similarity 0.42476341128349304\n",
      "Word castle , has similarity 0.3814162015914917\n",
      "Word white , has similarity 0.32747429609298706\n",
      "Word angry , has similarity 0.2994381785392761\n",
      "Word sea , has similarity 0.2897905111312866\n",
      "Word cat , has similarity 0.27486881613731384\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "\n",
    "king = nlp.vocab['king'].vector\n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector\n",
    "\n",
    "# Now we find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
    "new_vector = king - man + woman\n",
    "computed_similarities = []\n",
    "\n",
    "words = ['cat','apple','queen','castle','sea','shell','orange','phone' , 'tiffany'\n",
    "         ,'angry','book','white','land','study','crown','prince','dog',\n",
    "         'great','princess','elizabeth','wow','eat','dead','horrible']\n",
    "\n",
    "for word in words:\n",
    "    similarity = cosine_similarity(new_vector,nlp.vocab[word].vector)\n",
    "    computed_similarities.append((word, similarity))\n",
    "\n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "\n",
    "for a,b in computed_similarities[:10] : \n",
    "    print(f'Word {a} , has similarity {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'أسد').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'ذهب محمد الي الجامعة')\n",
    "\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
